{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d79356b674c9c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:20:38.107594Z",
     "start_time": "2024-07-29T07:20:36.131766Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:00.219870Z",
     "iopub.status.busy": "2024-07-29T11:48:00.219679Z",
     "iopub.status.idle": "2024-07-29T11:48:04.733041Z",
     "shell.execute_reply": "2024-07-29T11:48:04.732469Z",
     "shell.execute_reply.started": "2024-07-29T11:48:00.219847Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 19:48:02.890017: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 19:48:02.901222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 19:48:02.916335: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 19:48:02.920609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 19:48:02.931504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 19:48:03.889606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "from PIL import Image\n",
    "from modelscope import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:20:38.404348Z",
     "start_time": "2024-07-29T07:20:38.106723Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:04.735048Z",
     "iopub.status.busy": "2024-07-29T11:48:04.734515Z",
     "iopub.status.idle": "2024-07-29T11:48:04.737955Z",
     "shell.execute_reply": "2024-07-29T11:48:04.737419Z",
     "shell.execute_reply.started": "2024-07-29T11:48:04.735024Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def read_test_csv(csv_file_path_: str):\n",
    "    # 读取CSV文件\n",
    "    return pd.read_csv(csv_file_path_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c4518d8840c957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:20:38.404542Z",
     "start_time": "2024-07-29T07:20:38.368252Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:04.739125Z",
     "iopub.status.busy": "2024-07-29T11:48:04.738907Z",
     "iopub.status.idle": "2024-07-29T11:48:04.750894Z",
     "shell.execute_reply": "2024-07-29T11:48:04.750232Z",
     "shell.execute_reply.started": "2024-07-29T11:48:04.739101Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pandas import Series\n",
    "\n",
    "data_labels = {\n",
    "    \"skirt_length_labels\": [\"Invisible\", \"Short Length\", \"Knee Length\", \"Midi Length\", \"Ankle Length\", \"Floor Length\"],\n",
    "    \"coat_length_labels\": [\"Invisible\", \"High Waist Length\", \"Regular Length\", \"Long Length\", \"Micro Length\",\n",
    "                           \"Knee Length\", \"Midi Length\", \"Ankle&Floor Length\"],\n",
    "    \"collar_design_labels\": [\"Invisible\", \"Shirt Collar\", \"Peter Pan\", \"Puritan Collar\", \"Rib Collar\"],\n",
    "    \"lapel_design_labels\": [\"Invisible\", \"Notched\", \"Collarless\", \"Shawl Collar\", \"Plus Size Shawl\"],\n",
    "    \"neck_design_labels\": [\"Invisible\", \"Turtle Neck\", \"Ruffle Semi-High Collar\", \"Low Turtle Neck\", \"Draped Collar\"],\n",
    "    \"neckline_design_labels\": [\"Invisible\", \"Strapless Neck\", \"Deep V Neckline\", \"Straight Neck\", \"V Neckline\",\n",
    "                               \"Square Neckline\", \"Off Shoulder\", \"Round Neckline\", \"Sweat Heart Neck\",\n",
    "                               \"One\tShoulder Neckline\"],\n",
    "    \"pant_length_labels\": [\"Invisible\", \"Short Pant\", \"Mid Length\", \"3/4 Length\", \"Cropped Pant\", \"Full Length\"],\n",
    "    \"sleeve_length_labels\": [\"Invisible\", \"Sleeveless\", \"Cup Sleeves\", \"Short Sleeves\", \"Elbow Sleeves\", \"3/4 Sleeves\",\n",
    "                             \"Wrist Length\", \"Long Sleeves\", \"Extra Long Sleeves\"]\n",
    "}\n",
    "\n",
    "\n",
    "# 根据数据 Images/collar_design_labels/ceb3b249ac875ce56558c442501bbd68.jpg,collar_design_labels,nnnny 和 data_labes 中的键值对，将数据标签转换为一个对象\n",
    "\n",
    "class Attribute:\n",
    "    def __init__(self, image_path: str, key: str, values: List[str], value: str, may_values: List[str]):\n",
    "        self.key = key\n",
    "        self.values = values\n",
    "        self.value = value\n",
    "        self.may_values = may_values\n",
    "        self.image_path = f'{image_path}'\n",
    "        self.conversation = {}\n",
    "        self.format_key = self.key.replace(\"_\", \" \").replace(\"labels\", \"\")\n",
    "        self.query_content = f\"\"\"Instruction:: Recognize the {self.format_key} of Cloth Design\n",
    "                        Input:: You are a Senior Cloth Designer. Now you have a Cloth Picture. Please tell me what the {self.format_key} of this Cloth is after careful identification.\n",
    "                        Requires::\n",
    "                        - You should fully understand what the cloth is in the picture.\n",
    "                        - If you don't know what the picture shows, return \"Can't Recognize {self.image_path}.\"\n",
    "                        - Think about the answer step by step and you must choose the answer from [{','.join(self.values)}]\n",
    "                    \"\"\"\n",
    "        self.answer = f\"\"\"The [Cloth Design]'s [{self.format_key}] is [{self.value}]\"\"\" if not self.may_values else f\"\"\"The [Cloth Design]'s [{self.format_key}] is [{self.value}] or [::MayBe::{','.join(self.may_values)}]\"\"\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self.__dict__, ensure_ascii=False)\n",
    "\n",
    "    def to_json_conversation(self, ) -> Dict:\n",
    "        self.conversation = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": self.query_content,\n",
    "                    \"image\": self.image_path,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": self.answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        return self.conversation\n",
    "\n",
    "    def to_query_template(self) -> Dict:\n",
    "        original_example_messages = self.conversation[\"messages\"]\n",
    "        query = original_example_messages[0]\n",
    "        query_content = query[\"content\"]\n",
    "        format_key = self.key.replace(\"_\", \" \").replace(\"labels\", \"\")\n",
    "        #         new_query = f\"\"\"Instruction:: Recognize the {self.format_key} of Cloth Design\n",
    "        #                         Input:: You are a Senior Cloth Designer. Now you have a Cloth Picture. Please tell me what the {self.format_key} of this Cloth is after careful identification.\n",
    "\n",
    "        #                         Requires::\n",
    "        #                         - You should fully understand what the cloth is in the picture, and describe it.\n",
    "        #                         - If you don't know what the picture shows, return \"Can't Recognize {self.image_path}.\"\n",
    "        #                         - Think about the answer step by step and your answer must follow these rules:\n",
    "        #                             Rule-No1. Only choose the answer from [{','.join(self.values)}]\n",
    "\n",
    "        #                     \"\"\"\n",
    "        # query[\"content\"] = new_query\n",
    "        query[\"answer\"] = self.value\n",
    "        # print(query)\n",
    "        return query\n",
    "\n",
    "\n",
    "def convert_labels_to_object(base_img_path, data_labels_, label_list_: Series) -> Attribute:\n",
    "    # 分割标签字符串\n",
    "\n",
    "    image_path_ = label_list_[0]\n",
    "    # 获取属性键和属性值\n",
    "    attr_key = label_list_[1]\n",
    "    attr_value_index = label_list_[2]\n",
    "    # attr_value = 'nmmyn', 取出'y'的下标\n",
    "    position = attr_value_index.find('y')\n",
    "    # 查找属性值列表\n",
    "    values = data_labels_[attr_key]\n",
    "    # 获取属性值列表中对应下标的值\n",
    "    indices = [values[index] for index, char in enumerate(attr_value_index) if char == 'm']\n",
    "    attr_value = values[position] if position < len(values) else \"Not Exist\"\n",
    "    # 创建并返回属性对象\n",
    "    return Attribute(f'{base_img_path}/{image_path_}', attr_key, values, attr_value, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d9639fc506f466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:20:38.404596Z",
     "start_time": "2024-07-29T07:20:38.372646Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:04.752528Z",
     "iopub.status.busy": "2024-07-29T11:48:04.751916Z",
     "iopub.status.idle": "2024-07-29T11:48:04.759051Z",
     "shell.execute_reply": "2024-07-29T11:48:04.758539Z",
     "shell.execute_reply.started": "2024-07-29T11:48:04.752494Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def append_to_jsonl(jsonl_file_path, data):\n",
    "    # 追加数据到jsonl文件\n",
    "    with open(jsonl_file_path, 'a') as f:\n",
    "        f.write(json.dumps(data) + '\\n')\n",
    "\n",
    "\n",
    "def process_and_append(base_img_path, jsonl_file_path, df_, nums_: int) -> List[Attribute]:\n",
    "    # 检查文件是否存在，以及文件的大小\n",
    "    start_index = 0\n",
    "    attrs_ = []\n",
    "    nums_ = nums_ if nums_ else len(df_)\n",
    "    if os.path.exists(jsonl_file_path):\n",
    "        with open(jsonl_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                start_index += 1\n",
    "    datas_ = df_.sample(n=nums_)\n",
    "    # 从上次中断的地方开始处理\n",
    "    for index, row in tqdm(datas_.iterrows(), total=nums_, desc=\"Processing DataFrame\"):\n",
    "        if index < start_index:\n",
    "            continue\n",
    "        attribute_ = convert_labels_to_object(base_img_path, data_labels_=data_labels, label_list_=row)\n",
    "        append_to_jsonl(jsonl_file_path, attribute_.to_json_conversation())\n",
    "        attrs_.append(attribute_)\n",
    "    return attrs_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a6d2162941f83b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:20:43.495344Z",
     "start_time": "2024-07-29T07:20:38.379370Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:04.760387Z",
     "iopub.status.busy": "2024-07-29T11:48:04.759977Z",
     "iopub.status.idle": "2024-07-29T11:48:06.126350Z",
     "shell.execute_reply": "2024-07-29T11:48:06.125692Z",
     "shell.execute_reply.started": "2024-07-29T11:48:04.760356Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 调用模型进行推理\n",
    "device = \"cuda\"\n",
    "MODEL_PATH = \"ZhipuAI/glm-4v-9b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ZhipuAI/glm-4v-9b\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "# 模型进行推理\n",
    "def generate_input_(attribute_: Attribute):\n",
    "    query = attribute_.to_query_template()\n",
    "    # Function to load and process images\n",
    "    image_path = query[\"image\"]\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    print(f\"Image=> {image_path} | Query => {query['content']} | Expect Answer => {query['answer']}\")\n",
    "    # Function to prepare inputs for batch processing\n",
    "    input_ = tokenizer.apply_chat_template([{\"role\": \"user\", \"image\": image, \"content\": query[\"content\"]}],\n",
    "                                           add_generation_prompt=True, tokenize=True, return_tensors=\"pt\",\n",
    "                                           return_dict=True)  # chat mode\n",
    "    return input_\n",
    "\n",
    "\n",
    "def prepare_inputs(attributes_: List[Attribute]):\n",
    "    inputs_list = [generate_input_(attribute_) for attribute_ in attributes_]\n",
    "    # Combine inputs into a batch\n",
    "    input_ids_list = [inputs['input_ids'][0] for inputs in inputs_list]\n",
    "    padded_input_ids = torch.nn.utils.rnn.pad_sequence(input_ids_list, batch_first=True,\n",
    "                                                       padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask_ = torch.cat([padded_input_ids], dim=0)\n",
    "    return {'input_ids': padded_input_ids, 'attention_mask': attention_mask_}\n",
    "\n",
    "\n",
    "def infer_result_eval_(result_, attribute_: Attribute, ):\n",
    "    \"\"\"\n",
    "    评估模型的输出结果\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"correct\": attribute_.value in result_,\n",
    "        \"result\": result_,\n",
    "        \"image_path\": attribute_.image_path\n",
    "    }\n",
    "\n",
    "\n",
    "def model_run(attributes_, ):\n",
    "    # input_lists = prepare_inputs(attributes_)\n",
    "    # inputs = {k: v.to(device) for k, v in input_lists.items()}\n",
    "    model = AutoModel.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True\n",
    "    ).eval()\n",
    "    gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1}\n",
    "    eval_results_ = []\n",
    "    with torch.no_grad():\n",
    "        for attribute_ in attributes_:\n",
    "            start_time = time.time()\n",
    "            input_ = generate_input_(attribute_)\n",
    "            input_ = input_.to(device)\n",
    "            outputs = model.generate(**input_, **gen_kwargs)\n",
    "            outputs = outputs[:, input_['input_ids'].shape[1]:]\n",
    "            result = tokenizer.decode(outputs[0])\n",
    "            print(result)\n",
    "            end_time = time.time()\n",
    "            print(f\"推理时间: {end_time - start_time:.4f} 秒\")\n",
    "            eval_obj = infer_result_eval_(result, attribute_)\n",
    "            eval_results_.append(eval_obj)\n",
    "            # 将 result_obj 保存到 jsonl 文件中\n",
    "    return eval_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97bd76a2-d4dd-4d2c-9b5d-b730355dcb1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:20:43.499968Z",
     "start_time": "2024-07-29T07:20:43.495943Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:52.303504Z",
     "iopub.status.busy": "2024-07-29T11:48:52.303117Z",
     "iopub.status.idle": "2024-07-29T11:48:52.309084Z",
     "shell.execute_reply": "2024-07-29T11:48:52.308455Z",
     "shell.execute_reply.started": "2024-07-29T11:48:52.303480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# APP Block 代码启动模块\n",
    "def jsonl_file_creator(out_put_file, csv_file_path: str, image_folder_path: str,sample_num:int):\n",
    "    \"\"\"\n",
    "    csv_file_path: csv 文件, 用于构建对话数据\n",
    "    image_folder_path: 图片文件路径\n",
    "    \"\"\"\n",
    "    df = read_test_csv(csv_file_path)\n",
    "    #  从 df 数据(pandas)中的 dataFrame 中提取数据，并转换为 Attribute 对象列表\n",
    "    attributes = process_and_append(image_folder_path, out_put_file, df, sample_num)\n",
    "    # queries = [q.to_query_template() for q in attributes]\n",
    "    # print(queries)\n",
    "    # 运行模型进行评估\n",
    "    eval_objs = []\n",
    "    # model_run(attributes)\n",
    "    # 将评估结果, 放到 result 结果中.\n",
    "    if eval_objs:\n",
    "        with open(f'result-{version_}.jsonl', 'w', encoding='utf-8') as file:\n",
    "            file.write(json.dumps({\n",
    "                \"type\": \"META-INFO\",\n",
    "                \"version\": version_,\n",
    "                \"eval_objs\": attributes[0].to_query_template(),\n",
    "                \"totals\": len(eval_objs),\n",
    "                \"correct\": len([eval_obj for eval_obj in eval_objs if eval_obj[\"correct\"]]),\n",
    "            }, ensure_ascii=False))\n",
    "            for obj in eval_objs:\n",
    "                json_line = json.dumps(obj, ensure_ascii=False) + '\\n'\n",
    "                file.write(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5800a7f6-923b-4aa0-85fe-a73c5d254dcb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-29T07:20:43.497568Z"
    },
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T11:48:53.722935Z",
     "iopub.status.busy": "2024-07-29T11:48:53.722573Z",
     "iopub.status.idle": "2024-07-29T11:48:54.066379Z",
     "shell.execute_reply": "2024-07-29T11:48:54.065612Z",
     "shell.execute_reply.started": "2024-07-29T11:48:53.722911Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrame:   0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_3945/1771598973.py:82: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  image_path_ = label_list_[0]\n",
      "/tmp/ipykernel_3945/1771598973.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  attr_key = label_list_[1]\n",
      "/tmp/ipykernel_3945/1771598973.py:85: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  attr_value_index = label_list_[2]\n",
      "Processing DataFrame: 100%|██████████| 1000/1000 [00:00<00:00, 8025.13it/s]\n",
      "Processing DataFrame:   0%|          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_3945/1771598973.py:82: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  image_path_ = label_list_[0]\n",
      "/tmp/ipykernel_3945/1771598973.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  attr_key = label_list_[1]\n",
      "/tmp/ipykernel_3945/1771598973.py:85: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  attr_value_index = label_list_[2]\n",
      "Processing DataFrame: 100%|██████████| 1000/1000 [00:00<00:00, 8386.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据\n",
    "\n",
    "# 获取当前的日期和时间\n",
    "now = datetime.datetime.now()\n",
    "# 将日期和时间以及随机数字组合成 version_\n",
    "version_ = f\"{now.strftime('%Y%m%d%H%M')}\"\n",
    "\n",
    "\n",
    "\n",
    "jsonl_file_creator(f\"train_{version_}.jsonl\", 'r1_train/Tests/label.csv', '/mnt/workspace/data-clear/train_images', 1000)\n",
    "# 生成测试数据\n",
    "jsonl_file_creator(f\"dev_{version_}.jsonl\", 'r1_a/Tests/label.csv', '/mnt/workspace/data-clear/val_images', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493afab-f8cd-4766-ba52-711c58813b35",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-29T07:20:43.499Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
